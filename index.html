<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AIAA 6102 Artificial Intelligence Seminar II</title>
    <link rel="stylesheet" href="docs/styles.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ðŸ¤–</text></svg>">
</head>
<body>

<div class="hero-section">
  <div class="hero-content">
    <h1 class="hero-title">AIAA 6102 Artificial Intelligence Seminar II</h1>
    <p class="hero-subtitle">Exploring Cutting-Edge AI Technologies and Applications</p>
    <div class="hero-stats">
      <div class="stat">
        <span class="stat-number">12</span>
        <span class="stat-label">Invited Speakers</span>
      </div>
      <div class="stat">
        <span class="stat-number">8</span>
        <span class="stat-label">Session Videos</span>
      </div>
      <div class="stat">
        <span class="stat-number">24</span>
        <span class="stat-label">Credit Hours</span>
      </div>
    </div>
  </div>
</div>

## Course Overview

This seminar aims to deeply explore the latest developments in artificial intelligence, inviting industry experts and academic leaders to share their research findings and practical experiences. Through theoretical lectures, case studies, and interactive discussions, participants will gain a comprehensive understanding of the current state and future trends of AI technology.

## ðŸŽ“ Seminar Sessions

<div class="sessions-section">
  <div class="session-card">
    <div class="session-header">
      <div class="speaker-avatar">
        <img src="images/qiaoyu-tan.png" alt="Dr. Qiaoyu Tan">
      </div>
      <div class="speaker-basic-info">
        <h3><a href="#" target="_blank" class="speaker-name-link">Dr. Qiaoyu Tan</a></h3>
        <p class="speaker-title">Assistant Professor, NYU Shanghai</p>
        <div class="speaker-tags">
          <span class="tag">LLMs</span>
          <span class="tag">Graph Intelligence</span>
          <span class="tag">Reasoning</span>
          <span class="tag">Robustness</span>
        </div>
      </div>
      <div class="session-date">
        <span class="episode-number">Episode 3</span>
      </div>
    </div>
    <div class="session-content">
      <div class="session-section">
        <h4>Title: LLMs for Graph Intelligence: From Augmentation to Reasoning and Robustness</h4>
        <p class="session-abstract">
          Graphs are powerful data structures for modeling relational information in domains ranging from social networks to biomedical knowledge. As large language models (LLMs) advance rapidly, a key question arises: how can we harness their capabilities for graph-centric tasks? This talk presents a series of recent developments from our lab that explore this intersection. We begin by showing how LLMs can augment traditional graph neural networks, improving representation learning through instruction-tuned guidance and synthetic supervision. Next, we move beyond augmentation to examine how LLMs can act as reasoning engines over graph-structured data, both via prompt-based inference and fine-tuned multimodal Graph LLMs. Finally, we discuss our recent efforts on trustworthy Graph LLMs, where robustness and safety under distribution shift and adversarial attacks become critical. Together, these studies form a roadmap toward building more capable, generalizable, and reliable LLM-powered graph intelligence systems.
        </p>
      </div>
      <div class="session-section">
        <h4>Bio</h4>
        <p class="speaker-bio">
          Qiaoyu Tan is an Assistant Professor in the Computer Science department at NYU Shanghai, jointly affiliated with the Tandon School of Engineering at NYU. Before joining NYU Shanghai, he earned his Ph.D. from Texas A&M University under the supervision of Prof. Xia Hu, and received his B.Eng. from Southwest University. His research focuses on LLMs, autonomous agents, graph neural networks, knowledge graphs, and recommendation systems. He has published over 35 peer-reviewed papers in top-tier venues such as ICML, NeurIPS, KDD, WWW, ACL, CVPR, EMNLP, and WSDM, with h-index 27. He received the Best Student Paper Finalist at AMIA 2023. He has successfully led several research projects as Principal Investigator and actively contributes to the academic community, serving as the Ph.D. Symposium Chair for CIKM 2025 and Program Chair for ICHI 2023.
        </p>
      </div>
      <div class="session-video">
        <div class="video-thumbnail">
          <img src="https://via.placeholder.com/400x225/1F2937/FFFFFF?text=Session+3" alt="Session 3">
        </div>
        <div class="video-info">
          <p class="video-duration">Duration: 50 minutes</p>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="sessions-section">
  <div class="session-card">
    <div class="session-header">
      <div class="speaker-avatar">
        <img src="images/zhang-min.png" alt="Dr. Zhang Min">
      </div>
      <div class="speaker-basic-info">
        <h3><a href="#" target="_blank" class="speaker-name-link">Dr. Zhang Min</a></h3>
        <p class="speaker-title">Assistant Professor, East China Normal University</p>
        <div class="speaker-tags">
          <span class="tag">Causal Machine Learning</span>
          <span class="tag">Multimodal Large Models</span>
          <span class="tag">Intelligent Education</span>
          <span class="tag">Large Language Models</span>
        </div>
      </div>
      <div class="session-date">
        <span class="episode-number">Episode 2</span>
        <span class="date-day">12</span>
        <span class="date-month">September</span>
        <span class="date-time">13:30-14:20</span>
        <span class="date-location">Room 102, E4</span>
      </div>
    </div>
    <div class="session-content">
      <div class="session-section">
        <h4>Title: Comprehensive Robustness Evaluation of Multi-modal Large Language Model</h4>
        <p class="session-abstract">
          As the capabilities of multi-modal large language models like GPT-4o and Gemini continue to impress in understanding and generating complex data such as images, text, and audio, the issue of their robustness in real-world applications is becoming increasingly critical. What happens to a model's performance and reliability when it faces complex challenges like data noise, adversarial attacks, out-of-distribution data, and contradictions between different modalities? This is not only a central frontier in academia but also a cornerstone for ensuring the safe and reliable operation of AI systems in crucial fields like autonomous driving, medical diagnosis, and education. We will primarily discuss: (1) A Multi-dimensional Definition of Robustness: We will redefine the performance boundaries of multi-modal models in complex situations, moving beyond traditional accuracy metrics. (2) Robustness and Alignment: We will discuss how evaluation methods can guide a model's safety and value alignment, ensuring that it remains robust while adhering to human societal norms.
        </p>
      </div>
      <div class="session-section">
        <h4>Bio</h4>
        <p class="speaker-bio">
          Zhang Min is an Assistant Professor at East China Normal University, specializing in Causal Machine Learning, Multimodal Large Models, Intelligent Education, and Large Language Models. Her academic contributions include publishing over 30 papers at premier conferences such as ICML, NeurIPS, and KDD. She actively engages with the academic community by serving as a reviewer for these top-tier conferences and has organized multiple international workshops. Recognized for her excellence, she received numerous honors during her Ph.D. studies, including Outstanding Graduate, the National Scholarship, and the "Merit Student" of Zhejiang University. With extensive internship experience at China's leading internet companies, she successfully secured more than a dozen offers from top-tier tech firms in the 2024 fall recruitment cycle.
        </p>
      </div>
      <div class="session-video">
        <div class="video-thumbnail">
          <img src="https://via.placeholder.com/400x225/1F2937/FFFFFF?text=Session+2" alt="Session 2">
        </div>
        <div class="video-info">
          <p class="video-duration">Duration: 45 minutes</p>
          <p class="video-description">Online Zoom ID: 969 8340 8548<br>Passcode: 823262</p>
        </div>
      </div>
    </div>
  </div>
</div>


<div class="sessions-section">
  <div class="session-card">
    <div class="session-header">
      <div class="speaker-avatar">
        <img src="images/muhan-zhang.png" alt="Dr. Muhan Zhang">
      </div>
      <div class="speaker-basic-info">
        <h3><a href="https://muhanzhang.github.io/" target="_blank" class="speaker-name-link">Dr. Muhan Zhang</a></h3>
        <p class="speaker-title">Institute for Artificial Intelligence, Peking University</p>
        <div class="speaker-tags">
          <span class="tag">Graph Neural Networks</span>
          <span class="tag">Machine Learning</span>
          <span class="tag">Large Language Models</span>
        </div>
      </div>
      <div class="session-date">
        <span class="episode-number">Episode 1</span>
        <span class="date-day">5</span>
        <span class="date-month">September</span>
        <span class="date-time">13:30-14:20</span>
        <span class="date-location">Room 102, E4</span>
      </div>
    </div>
    <div class="session-content">
      <div class="session-section">
        <h4>Title: TransMLA: Multi-Head Latent Attention Is All You Need</h4>
        <p class="session-abstract">We present TransMLA, a framework that seamlessly converts any GQA-based pre-trained model into an MLA-based model. Our approach enables direct compatibility with DeepSeek's codebase, allowing these models to fully leverage DeepSeek-specific optimizations such as vLLM and SGlang. By compressing 93% of the KV cache in LLaMA-2-7B, TransMLA achieves a 10.6x inference speedup at an 8K context length while preserving meaningful output quality. Additionally, the model requires only 6 billion tokens for fine-tuning to regain performance on par with the original across multiple benchmarks. TransMLA offers a practical solution for migrating GQA-based models to the MLA structure. When combined with DeepSeek's advanced features, such as FP8 quantization and Multi-Token Prediction, even greater inference acceleration can be realized.</p>
      </div>
      <div class="session-section">
        <h4>Bio</h4>
        <p class="speaker-bio">Dr. Muhan Zhang is an assistant professor and assistant to the dean at Institute for Artificial Intelligence, Peking University. He is recipient of the National Excellent Youth (Overseas) Project, and Boya and Weiming Young Scholars of Peking University. He graduated from the IEEE pilot class of Shanghai Jiao Tong University in 2015 and obtained his Ph.D. in Computer Science from Washington University in St. Louis in 2019. From 2019 to 2021, he was a research scientist at Meta AI. He was awarded the AI 2000 most influential scholar honorable mentions by Aminer, and Elsevier top 2% scientist worldwide for multiple years. As a pioneer researcher of Graph Neural Networks, his DGCNN algorithm for graph classification was selected as one of the top ten most influential papers at AAAI-2018 and has been cited over 2000 times. His SEAL algorithm for link prediction significantly broadened the applicability of GNNs on multi-node tasks and has been cited over 2500 times. He regularly serves as an area chair for NeurIPS, ICML, ICLR and other top conferences, and he is a reviewer for top journals such as JMLR, TPAMI, TNNLS, TKDE, TSP, AOAS, and JAIR. He teaches Machine Learning and Introduction to Artificial Intelligence at Peking University.</p>
      </div>
      <div class="session-video">
        <div class="video-thumbnail">
          <img src="https://via.placeholder.com/400x225/1F2937/FFFFFF?text=Session+1" alt="Session 1">
        </div>
        <div class="video-info">
          <p class="video-duration">Duration: 45 minutes</p>
          <p class="video-description">Online Zoom ID: 969 8340 8548<br>Passcode: 823262</p>
          <a href="docs/slides/muhan-zhang-slides.pdf" class="watch-button" target="_blank">Slides (PDF)</a>
        </div>
      </div>
    </div>
  </div>
</div>




---

*Â© 2024 AIAA 6102 Artificial Intelligence Seminar II. All rights reserved.*

</body>
</html>

